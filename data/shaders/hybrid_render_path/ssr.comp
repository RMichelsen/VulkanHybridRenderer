#version 460
#extension GL_GOOGLE_include_directive : require
#include "../common.glsl"
#include "../../../src/rendering_backend/glsl_common.h"

layout(local_size_x = 8, local_size_y = 8) in;

layout(set = 3, binding = 0) uniform sampler2D albedo;
layout(set = 3, binding = 1) uniform sampler2D world_space_normals_and_object_ids;
layout(set = 3, binding = 2) uniform sampler2D motion_vectors_and_metallic_roughness;
layout(set = 3, binding = 3) uniform sampler2D depth;
layout(set = 3, binding = 4, r16f) writeonly uniform image2D screen_space_reflections;

layout(push_constant) uniform PushConstants { SSRPushConstants pc; };

vec2 view_space_to_screen_coordinates(vec3 v) {
	vec4 clip_space = pfd.camera_proj * vec4(v, 1.0);
	clip_space.xyz /= clip_space.w;
	return (clip_space.xy * 0.5 + 0.5) * pfd.display_size;
}

vec3 compute_lighting(vec2 uv) {
	vec3 albedo = texture(albedo, uv).rgb;
	vec3 position = get_world_space_position(texture(depth, uv).x, uv);
	vec2 metallic_roughness = texture(motion_vectors_and_metallic_roughness, uv).zw;
		
	vec3 camera_position = vec3(pfd.camera_view_inverse[3].xyz);
	vec3 V = normalize(camera_position - position);
	vec3 L = -pfd.directional_light.direction.xyz;
	vec3 N = texture(world_space_normals_and_object_ids, uv).xyz;
	vec3 H = normalize(L + V);
		
	float min_roughness = 0.04;
	float metallic = clamp(metallic_roughness.x, 0.0, 1.0);
	float roughness = clamp(metallic_roughness.y, min_roughness, 1.0);
		
	// Assume quite low ambient contribution, 
	// in reality would need to trace AO rays, but too expensive
	float ambient_factor = PI_INVERSE * 0.2;
	vec3 light_intensity = pfd.directional_light.intensity.xyz;
	vec3 light_color = pfd.directional_light.color.rgb;
		
	vec3 f0 = vec3(0.04);
	f0 = mix(f0, albedo, metallic);
	vec3 F = fresnel_schlick(f0, H, V);
		
	vec3 ambient_lighting = albedo * ambient_factor;
	vec3 diffuse_lighting = diffuse_brdf(metallic, albedo, F);
	vec3 specular_lighting = specular_brdf(roughness, F, V, L, N, H);
	vec3 lighting = ambient_lighting + (diffuse_lighting + specular_lighting) * max(dot(N, L), 0.0) * light_intensity * light_color;

	return lighting;
}

void main() {
	vec2 coords = ivec2(gl_GlobalInvocationID.xy) * pfd.display_size_inverse;
	float fragment_depth = texture(depth, coords).x;

	vec3 P = get_view_space_position(fragment_depth, coords);
	vec3 N = mat3(pfd.camera_view) * texture(world_space_normals_and_object_ids, coords).xyz;
	vec3 I = normalize(P);
	vec3 reflected_dir = normalize(reflect(I, N));

	vec3 start_position = P;
	vec3 end_position = P + reflected_dir * pc.ray_distance;

	// Project start and end positions from view space into screen coordinates,
	// since we are ray marching in screen space.
	vec2 start_position_coords = view_space_to_screen_coordinates(start_position);
	vec2 end_position_coords = view_space_to_screen_coordinates(end_position);

	if(fragment_depth == 0.0 || 
	   end_position_coords.x < 0 || end_position_coords.x >= pfd.display_size.x ||
	   end_position_coords.y < 0 || end_position_coords.y >= pfd.display_size.y ||
	   reflected_dir.z > 0.0) {
		imageStore(
			screen_space_reflections,
			ivec2(gl_GlobalInvocationID.xy),
			vec4(0.0)
		);
		return;
	}

	float delta_x = abs(end_position_coords.x - start_position_coords.x);
	float delta_y = abs(end_position_coords.y - start_position_coords.y);
	float number_of_steps = max(delta_x, delta_y) * pc.resolution;
	vec2 delta = vec2(delta_x, delta_y) / max(number_of_steps, 1e-4);

	bool ready_to_binary_search = false;
	vec2 sample_uv = start_position_coords.xy * pfd.display_size_inverse;
	float sample_depth = 0.0;
	float ray_depth = 0.0;
	float miss_fraction = 0.0;
	float complete_fraction = 0.0;
	for(int i = 0; i < number_of_steps; ++i) {
		float fraction = float(i) / float(number_of_steps);
		sample_uv += (delta * pfd.display_size_inverse);
		sample_depth = get_view_space_position(texture(depth, sample_uv).x, sample_uv).z;
		ray_depth = (start_position.z * end_position.z) / mix(end_position.z, start_position.z, fraction);
		float depth_delta = ray_depth - sample_depth;
		if(depth_delta < 0 && depth_delta > pc.thickness) {
			ready_to_binary_search = true;
			complete_fraction = fraction;
			break;
		}
		else {
			miss_fraction = fraction;
		}
	}

	if(!ready_to_binary_search) {
		imageStore(
			screen_space_reflections,
			ivec2(gl_GlobalInvocationID.xy),
			vec4(0.0)
		);
		return;
	}

	float midway_fraction = (miss_fraction + complete_fraction) * 0.5;
	for(int i = 0; i < pc.bsearch_steps; ++i) {
		sample_uv = mix(start_position_coords.xy, end_position_coords.xy, midway_fraction) * pfd.display_size_inverse;
		sample_depth = get_view_space_position(texture(depth, sample_uv).x, sample_uv).z;
		ray_depth = (start_position.z * end_position.z) / mix(end_position.z, start_position.z, midway_fraction);
		float depth_delta = ray_depth - sample_depth;
		if(depth_delta < 0 && depth_delta > pc.thickness) {
			midway_fraction = (miss_fraction + midway_fraction) * 0.5;
		}
		else {
			float tmp = midway_fraction;
			midway_fraction = (midway_fraction * 1.5 - miss_fraction * 0.5);
			miss_fraction = tmp;
		}
	}

	imageStore(
		screen_space_reflections,
		ivec2(gl_GlobalInvocationID.xy),
		vec4(compute_lighting(sample_uv), 1.0)
	);
//	float prev_depth = distance(P, camera_position);
//	float current_depth = 0.0;
//	float ray_increment = 1e-6;
//	float increment_size = 0.1;
//	for(int i = 0; i < 128; ++i) {
//		ray_increment += increment_size;
//
//		vec3 point_along_ray = P + reflected_dir * ray_increment;
//		current_depth = distance(point_along_ray, camera_position);
//
//		vec4 point_along_ray_clip_space = pfd.camera_proj * pfd.camera_view * vec4(point_along_ray, 1.0);
//		vec2 point_along_ray_uv = (point_along_ray_clip_space.xy / point_along_ray_clip_space.w) * 0.5 + 0.5;
//
//		float sampled_depth = distance(get_world_space_position(texture(depth, point_along_ray_uv).x, point_along_ray_uv), camera_position);
//		if(sampled_depth < current_depth && sampled_depth > (prev_depth - 0.2)) {
//			// Binary search to approximate exact intersection
//			float start = 0.0;
//			float end = increment_size;
//			vec2 point_along_ray_uv_adj = vec2(0.0);
//			for(int j = 0; j < 4; ++j) {
//				float middle_point = (start + end) * 0.5;
//				vec3 point_along_ray_adj = P + reflected_dir * ((ray_increment - increment_size) + middle_point);
//				float mid_depth = distance(point_along_ray_adj, camera_position);
//
//				vec4 point_along_ray_clip_space_adj = pfd.camera_proj * pfd.camera_view * vec4(point_along_ray_adj, 1.0);
//				point_along_ray_uv_adj = (point_along_ray_clip_space_adj.xy / point_along_ray_clip_space_adj.w) * 0.5 + 0.5;
//				float sampled_depth_adj = distance(get_world_space_position(texture(depth, point_along_ray_uv_adj).x, point_along_ray_uv_adj), camera_position);
//
//				if(sampled_depth_adj < mid_depth) {
//					end = middle_point;
//				}
//				else {
//					start = middle_point;
//				}
//			}
//
//			if(point_along_ray_uv_adj.x < 0.0 || point_along_ray_uv_adj.x > 1.0 || 
//			   point_along_ray_uv_adj.y < 0.0 || point_along_ray_uv_adj.y > 1.0) {
//				break;
//			}
//
//			vec3 albedo = texture(albedo, point_along_ray_uv_adj).rgb;
//			vec3 position = get_world_space_position(texture(depth, point_along_ray_uv_adj).x, point_along_ray_uv_adj);
//			vec2 metallic_roughness = texture(motion_vectors_and_metallic_roughness, point_along_ray_uv_adj).zw;
//
//			vec3 V = normalize(camera_position - position);
//			vec3 L = -pfd.directional_light.direction.xyz;
//			vec3 N = texture(world_space_normals_and_object_ids, point_along_ray_uv_adj).xyz;
//			vec3 H = normalize(L + V);
//
//			float min_roughness = 0.04;
//			float metallic = clamp(metallic_roughness.x, 0.0, 1.0);
//			float roughness = clamp(metallic_roughness.y, min_roughness, 1.0);
//
//			// Assume quite low ambient contribution, 
//			// in reality would need to trace AO rays, but too expensive
//			float ambient_factor = PI_INVERSE * 0.2;
//			vec3 light_intensity = pfd.directional_light.intensity.xyz;
//			vec3 light_color = pfd.directional_light.color.rgb;
//
//			vec3 f0 = vec3(0.04);
//			f0 = mix(f0, albedo, metallic);
//			vec3 F = fresnel_schlick(f0, H, V);
//
//			vec3 ambient_lighting = albedo * ambient_factor;
//			vec3 diffuse_lighting = diffuse_brdf(metallic, albedo, F);
//			vec3 specular_lighting = specular_brdf(roughness, F, V, L, N, H);
//			vec3 lighting = ambient_lighting + (diffuse_lighting + specular_lighting) * max(dot(N, L), 0.0) * light_intensity * light_color;
//
//			imageStore(
//				screen_space_reflections,
//				ivec2(gl_GlobalInvocationID.xy),
//				vec4(lighting, 1.0)
//			);
//			return;
//		}
//
//		prev_depth = current_depth;
//	}
}
