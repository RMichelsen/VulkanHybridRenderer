#version 460
#extension GL_GOOGLE_include_directive : require
#include "../common.glsl"
#include "../../../src/rendering_backend/glsl_common.h"

layout(local_size_x = 8, local_size_y = 8) in;

layout(set = 3, binding = 0) uniform sampler2D albedo;
layout(set = 3, binding = 1) uniform sampler2D world_space_normals_and_linear_depths;
layout(set = 3, binding = 2) uniform sampler2D motion_vectors_and_metallic_roughness;
layout(set = 3, binding = 3) uniform sampler2D depth;
layout(set = 3, binding = 4, r16f) writeonly uniform image2D screen_space_reflections;

void main() {
	vec2 coords = ivec2(gl_GlobalInvocationID.xy) * pfd.display_size_inverse;
	float fragment_depth = texture(depth, coords).x;
	if(fragment_depth == 0.0) {
		imageStore(
			screen_space_reflections,
			ivec2(gl_GlobalInvocationID.xy),
			vec4(0.0)
		);
		return;
	}

	vec3 P = get_world_space_position(fragment_depth, coords);
	vec3 N = oct_decode_to_vec3(texture(world_space_normals_and_linear_depths, coords).rg);

	vec3 camera_position = vec3(pfd.camera_view_inverse[3].xyz);
	vec3 I = normalize(P - camera_position);
	vec3 reflected_dir = normalize(reflect(I, N));

	float prev_depth = distance(P, camera_position);
	float current_depth = 0.0;
	float ray_increment = 1e-6;
	float increment_size = 0.1;
	for(int i = 0; i < 128; ++i) {
		ray_increment += increment_size;

		vec3 point_along_ray = P + reflected_dir * ray_increment;
		current_depth = distance(point_along_ray, camera_position);

		vec4 point_along_ray_clip_space = pfd.camera_proj * pfd.camera_view * vec4(point_along_ray, 1.0);
		vec2 point_along_ray_uv = (point_along_ray_clip_space.xy / point_along_ray_clip_space.w) * 0.5 + 0.5;

		float sampled_depth = distance(get_world_space_position(texture(depth, point_along_ray_uv).x, point_along_ray_uv), camera_position);
		if(sampled_depth < current_depth && sampled_depth > (prev_depth - 0.2)) {
			// Binary search to approximate exact intersection
			float start = 0.0;
			float end = increment_size;
			vec2 point_along_ray_uv_adj = vec2(0.0);
			for(int j = 0; j < 4; ++j) {
				float middle_point = (start + end) * 0.5;
				vec3 point_along_ray_adj = P + reflected_dir * ((ray_increment - increment_size) + middle_point);
				float mid_depth = distance(point_along_ray_adj, camera_position);

				vec4 point_along_ray_clip_space_adj = pfd.camera_proj * pfd.camera_view * vec4(point_along_ray_adj, 1.0);
				point_along_ray_uv_adj = (point_along_ray_clip_space_adj.xy / point_along_ray_clip_space_adj.w) * 0.5 + 0.5;
				float sampled_depth_adj = distance(get_world_space_position(texture(depth, point_along_ray_uv_adj).x, point_along_ray_uv_adj), camera_position);

				if(sampled_depth_adj < mid_depth) {
					end = middle_point;
				}
				else {
					start = middle_point;
				}
			}

			if(point_along_ray_uv_adj.x < 0.0 || point_along_ray_uv_adj.x > 1.0 || 
			   point_along_ray_uv_adj.y < 0.0 || point_along_ray_uv_adj.y > 1.0) {
				break;
			}

			vec3 albedo = texture(albedo, point_along_ray_uv_adj).rgb;
			vec3 position = get_world_space_position(texture(depth, point_along_ray_uv_adj).x, point_along_ray_uv_adj);
			vec2 metallic_roughness = texture(motion_vectors_and_metallic_roughness, point_along_ray_uv_adj).zw;

			vec3 V = normalize(camera_position - position);
			vec3 L = -pfd.directional_light.direction.xyz;
			vec3 N = oct_decode_to_vec3(texture(world_space_normals_and_linear_depths, point_along_ray_uv_adj).rg);
			vec3 H = normalize(L + V);

			float min_roughness = 0.04;
			float metallic = clamp(metallic_roughness.x, 0.0, 1.0);
			float roughness = clamp(metallic_roughness.y, min_roughness, 1.0);

			// Assume quite low ambient contribution, 
			// in reality would need to trace AO rays, but too expensive
			float ambient_factor = PI_INVERSE * 0.2;
			vec3 light_intensity = pfd.directional_light.intensity.xyz;
			vec3 light_color = pfd.directional_light.color.rgb;

			vec3 f0 = vec3(0.04);
			f0 = mix(f0, albedo, metallic);
			vec3 F = fresnel_schlick(f0, H, V);

			vec3 ambient_lighting = albedo * ambient_factor;
			vec3 diffuse_lighting = diffuse_brdf(metallic, albedo, F);
			vec3 specular_lighting = specular_brdf(roughness, F, V, L, N, H);
			vec3 lighting = ambient_lighting + (diffuse_lighting + specular_lighting) * max(dot(N, L), 0.0) * light_intensity * light_color;

			imageStore(
				screen_space_reflections,
				ivec2(gl_GlobalInvocationID.xy),
				vec4(lighting, 1.0)
			);
			return;
		}

		prev_depth = current_depth;
	}

	imageStore(
		screen_space_reflections,
		ivec2(gl_GlobalInvocationID.xy),
		vec4(0.0)
	);
}
